{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk, re, pprint\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "tweet = \"I subscribe to Luca Mezzalira take on state management. And just for you to know.. white beards are class!! Now let me observe your talk.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('subscribe', 'VBP'), ('to', 'TO'), ('Luca', 'NNP'), ('Mezzalira', 'NNP'), ('take', 'VB'), ('on', 'IN'), ('state', 'NN'), ('management', 'NN'), ('.', '.'), ('And', 'CC'), ('just', 'RB'), ('for', 'IN'), ('you', 'PRP'), ('to', 'TO'), ('know..', 'VB'), ('white', 'JJ'), ('beards', 'NNS'), ('are', 'VBP'), ('class', 'NN'), ('!', '.'), ('!', '.'), ('Now', 'RB'), ('let', 'VB'), ('me', 'PRP'), ('observe', 'VB'), ('your', 'PRP$'), ('talk', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "def preprocess(tweet):\n",
    "    tokenized_words = nltk.word_tokenize(tweet)\n",
    "    pos_tagged = nltk.pos_tag(tokenized_words)\n",
    "    return pos_tagged\n",
    "\n",
    "preprocessed_tweet = preprocess(tweet)\n",
    "\n",
    "print(preprocessed_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('subscribe', 'VBP'), ('to', 'TO'), ('Luca', 'NNP'), ('Mezzalira', 'NNP'), ('take', 'VB'), ('on', 'IN'), ('state', 'NN'), ('management', 'NN'), ('.', '.'), ('And', 'CC'), ('just', 'RB'), ('for', 'IN'), ('you', 'PRP'), ('to', 'TO'), ('know..', 'VB'), ('white', 'JJ'), ('beards', 'NNS'), ('are', 'VBP'), ('class', 'NN'), ('!', '.'), ('!', '.'), ('Now', 'RB'), ('let', 'VB'), ('me', 'PRP'), ('observe', 'VB'), ('your', 'PRP$'), ('talk', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Chunking:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# This grammar is described in the paper by S. N. Kim,\n",
    "# T. Baldwin, and M.-Y. Kan.\n",
    "# Evaluating n-gram based evaluation metrics for automatic\n",
    "# keyphrase extraction.\n",
    "# Technical report, University of Melbourne, Melbourne 2010.\n",
    "grammar = r\"\"\"\n",
    "    NBAR:\n",
    "        # Nouns and Adjectives, terminated with Nouns\n",
    "        {<NN.*|JJ>*<NN.*>}\n",
    "\n",
    "    NP:\n",
    "        # Noun Phrase Chunking\n",
    "        {<NBAR>}\n",
    "        # Above, connected with in/of/etc...\n",
    "        {<NBAR><IN><NBAR>}\n",
    "\"\"\"\n",
    "chunker = nltk.RegexpParser(grammar)\n",
    "tree = chunker.parse(preprocessed_tweet)\n",
    "\n",
    "print(preprocessed_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['luca', 'mezzalira', 'state', 'management', 'white', 'beards', 'class', 'talk']\n"
     ]
    }
   ],
   "source": [
    "# Helper function to traverse the graph and extract the NP\n",
    "def leaves(tree):\n",
    "    \"\"\"Finds NP (nounphrase) leaf nodes of a chunk tree.\"\"\"\n",
    "    for subtree in tree.subtrees(filter = lambda t: t.label()=='NP'):\n",
    "        yield subtree.leaves()\n",
    "\n",
    "def acceptable_word(word):\n",
    "    \"\"\"Checks conditions for acceptable word: length, stopword.\"\"\"\n",
    "    #bool(2 <= len(word) <= 40 and word.lower() not in stopwords)\n",
    "    return word not in stopwords\n",
    "\n",
    "# Walking the tree and Normalisation\n",
    "\"\"\"\n",
    "\n",
    "Normalisation may consist of lower-casing words, removing stop-words which appear in many documents \n",
    "(i.e. if, the, a…), stemming (i.e. cars → car), and lemmatizing (i.e. drove, drives, rode → drive). \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_terms(tree):\n",
    "    for leaf in leaves(tree):\n",
    "        term = [ word.lower() for word, tag in leaf if acceptable_word(word) ]\n",
    "        yield term\n",
    "\n",
    "terms = get_terms(tree)\n",
    "\n",
    "\n",
    "extracted_keywords = []\n",
    "for term in terms:\n",
    "    for word in term:\n",
    "        extracted_keywords.append(word)\n",
    "print(extracted_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
