{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk, re, pprint\n",
    "from nltk.corpus import stopwords\n",
    "import functools\n",
    "\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"We are making great progress with healthcare. ObamaCare is imploding and will only get worse. Republicans coming together to get job done!\",\n",
    "    \"'U.S. Consumer Comfort Just Reached Its Highest Level in a Decade' ??https://t.co/S8nZgmeMMV https://t.co/xC0piRa6eP\",\n",
    "    \"For eight years Russia 'ran over' President Obama, got stronger and stronger, picked-off Crimea and added missiles. Weak! @foxandfriends\",\n",
    "    \"122 vicious prisoners, released by the Obama Administration from Gitmo, have returned to the battlefield. Just another terrible decision!\",\n",
    "    \"MAKE AMERICA GREAT AGAIN!\",\n",
    "    \"North Korea just stated that it is in the final stages of developing a nuclear weapon capable of reaching parts of the U.S. It won't happen!\",\n",
    "    \"Russia has more warheads than ever, N Korea is testing nukes, and Iran got a sweetheart deal to keep theirs. Thanks, @HillaryClinton.\",\n",
    "    \"In Bangladesh, hostages were immediately killed by ISIS terrorists if they were unable to cite a verse from the Koran. 20 were killed!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tweet):\n",
    "    tokenized_words = nltk.word_tokenize(tweet)\n",
    "    pos_tagged = nltk.pos_tag(tokenized_words)\n",
    "    return pos_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_tweets = [preprocess(tweet) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Chunking:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# This grammar is described in the paper by S. N. Kim,\n",
    "# T. Baldwin, and M.-Y. Kan.\n",
    "# Evaluating n-gram based evaluation metrics for automatic\n",
    "# keyphrase extraction.\n",
    "# Technical report, University of Melbourne, Melbourne 2010.\n",
    "grammar = r\"\"\"\n",
    "    NBAR:\n",
    "        # Nouns and Adjectives, terminated with Nouns\n",
    "        {<NN.*|JJ>*<NN.*>}\n",
    "\n",
    "    NP:\n",
    "        # Noun Phrase Chunking\n",
    "        {<NBAR>}\n",
    "        # Above, connected with in/of/etc...\n",
    "        {<NBAR><IN><NBAR>}\n",
    "\"\"\"\n",
    "trees = []\n",
    "chunker = nltk.RegexpParser(grammar)\n",
    "for index, tweet in enumerate(preprocessed_tweets):\n",
    "    trees.append(chunker.parse(tweet))\n",
    "#trees[0].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to traverse the graph and extract the NP\n",
    "def leaves(tree):\n",
    "    \"\"\"Finds NP (nounphrase) leaf nodes of a chunk tree.\"\"\"\n",
    "    for subtree in tree.subtrees(filter = lambda t: t.label()=='NP'):\n",
    "        yield subtree.leaves()\n",
    "\n",
    "def acceptable_word(word):\n",
    "    \"\"\"Checks conditions for acceptable word: length, stopword.\"\"\"\n",
    "    #bool(2 <= len(word) <= 40 and word.lower() not in stopwords)\n",
    "    return word not in stopwords\n",
    "\n",
    "def get_terms(tree):\n",
    "    for leaf in leaves(tree):\n",
    "        term = [ word.lower() for word, tag in leaf if acceptable_word(word) ]\n",
    "        yield term\n",
    "\n",
    "terms = []\n",
    "for index, tree in enumerate(trees):\n",
    "    terms.append(get_terms(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['great', 'progress', 'healthcare', 'obamacare', 'republicans', 'job'], ['consumer', 'comfort', 'just', 'highest', 'level', 'decade', 'https', '//t.co/s8nzgmemmv', 'https', '//t.co/xc0pira6ep'], ['years', 'russia', 'president', 'obama', 'picked-off', 'crimea', 'missiles', 'foxandfriends'], ['vicious', 'prisoners', 'obama', 'administration', 'gitmo', 'battlefield', 'just', 'terrible', 'decision'], ['make', 'america', 'great', 'again'], ['north', 'korea', 'final', 'stages', 'nuclear', 'weapon', 'parts', 'u.s'], ['russia', 'warheads', 'n', 'korea', 'nukes', 'iran', 'sweetheart', 'deal', 'thanks', '@', 'hillaryclinton'], ['bangladesh', 'hostages', 'isis', 'terrorists', 'verse', 'koran']]\n"
     ]
    }
   ],
   "source": [
    "def convert2Dinto1D(terms):\n",
    "    return functools.reduce(lambda x,y :x+y ,[word for word in terms])\n",
    "\n",
    "\n",
    "extracted_keywords = []\n",
    "for term in terms:\n",
    "    extracted_keywords.append(convert2Dinto1D(term))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['great', 'progress', 'healthcare', 'obamacare', 'republicans', 'job']\n",
      "['consumer', 'comfort', 'just', 'highest', 'level', 'decade', 'https', '//t.co/s8nzgmemmv', 'https', '//t.co/xc0pira6ep']\n",
      "['years', 'russia', 'president', 'obama', 'picked-off', 'crimea', 'missiles', 'foxandfriends']\n",
      "['vicious', 'prisoners', 'obama', 'administration', 'gitmo', 'battlefield', 'just', 'terrible', 'decision']\n",
      "['make', 'america', 'great', 'again']\n",
      "['north', 'korea', 'final', 'stages', 'nuclear', 'weapon', 'parts', 'u.s']\n",
      "['russia', 'warheads', 'n', 'korea', 'nukes', 'iran', 'sweetheart', 'deal', 'thanks', '@', 'hillaryclinton']\n",
      "['bangladesh', 'hostages', 'isis', 'terrorists', 'verse', 'koran']\n"
     ]
    }
   ],
   "source": [
    "# Printing Results\n",
    "\n",
    "for keywords in extracted_keywords:\n",
    "    print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
